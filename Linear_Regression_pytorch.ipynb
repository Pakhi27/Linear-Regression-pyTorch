{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGZQkJwEWNVe4TbipeMap3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pakhi27/Linear-Regression-pyTorch/blob/main/Linear_Regression_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O7WO6VeDZhnK"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ùëè=‚àí1,ùë§=2\n",
        "# ùë¶ÃÇ =‚àí1+2ùë•\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "metadata": {
        "id": "Sozgr3dPZnIA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "metadata": {
        "id": "tYfXY3NGZu6V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w8g0UYFZzXi",
        "outputId": "480ce8ef-6e1c-42f0-c3da-f9af212b2f22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For multiple input\n",
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26zm5BiYZ0aX",
        "outputId": "b544c321-646c-4db8-d101-7a0545108585"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9KZC_-7Z-l6",
        "outputId": "a5430454-85e7-425f-9e9b-33414a6f4d13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice: Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "print(\"The shape of x: \", x.shape)\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9C_knotaCsr",
        "outputId": "381f0725-69c2-4ec3-e6fa-88e63955c977"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of x:  torch.Size([3, 1])\n",
            "The prediction:  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Linear"
      ],
      "metadata": {
        "id": "n4I9auyoaJx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Class Linear\n",
        "\n",
        "from torch.nn import Linear"
      ],
      "metadata": {
        "id": "3A0GR0PbaMb6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed-parameters are randomly initialized\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEjXbrKPaPJ_",
        "outputId": "9bdb5a57-eb56-4788-eefb-42414d4316f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d0db7fac250>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Linear Regression Model, and print out the parameters-w,b\n",
        "\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wknYQrEOaVV-",
        "outputId": "18de9385-3a28-43b4-ec8d-fa3c55d4197e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A method state_dict() Returns a Python dictionary object corresponding to the layers of each parameter tensor."
      ],
      "metadata": {
        "id": "O7uYzdP-abjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIDNmE8Laks0",
        "outputId": "9a328a35-4263-44ec-e545-7e15220b08fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWR74MKvapm5",
        "outputId": "6c312b08-8b79-4123-be19-a6cfe903a0e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single prediction\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFwWjmMBatYo",
        "outputId": "c424e5a1-05e1-4afe-f88a-b2d7effbdcb3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple predictions:"
      ],
      "metadata": {
        "id": "cOxaBSQGaxzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEzdMW-ea19Z",
        "outputId": "e78874c7-5e7d-407c-b47b-4a9dea1f5bb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x tensor using the linear regression model lr."
      ],
      "metadata": {
        "id": "x60eYj9Na61l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gX2wZmPa9xM",
        "outputId": "4055aede-c345-450d-c254-d87c4eb1c65f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class custom modules"
      ],
      "metadata": {
        "id": "sKJIHoRrbD5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "BMQVLUN4bG4h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us define the class:\n",
        "# Customize Linear Regression Class\n",
        "\n",
        "class LR(nn.Module):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "\n",
        "        # Inherit from parent\n",
        "        super(LR, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "as0ZJhoDbRC1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object by using the constructor. Print out the parameters we get and the model."
      ],
      "metadata": {
        "id": "gfn-rex6bWgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the linear regression model. Print out the parameters.\n",
        "\n",
        "lr = LR(1, 1)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxmByxQAbZ8c",
        "outputId": "c526bffa-6f4e-4197-c92a-f756ce17dea8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKScGkUbdFl",
        "outputId": "780f93da-4f2e-438f-9843-05c7c910c59b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mutiple samples..\n",
        "# Try our customize linear regression model with multiple input\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWfI1olnbgCt",
        "outputId": "48709e81-5bbe-44b1-fb98-a6880b92bbd7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.2755],\n",
            "        [0.0816]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcj_KlT6bl44",
        "outputId": "4995eff0-1978-49b8-d4b2-d49d1e692406"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZE58CVEboCA",
        "outputId": "cf30e134-0998-4478-a7a4-d88705fbdb69"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[ 0.2755],\n",
            "        [ 0.0816],\n",
            "        [-0.1122]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}